---
title: "Credit Card Customer Attrition Analysis"
date: "`r Sys.Date()`"
---

## 1. Setup and Data Loading

This section loads all necessary libraries and imports the credit card customer dataset. We use the `tidymodels` framework for our analysis and modeling pipeline.

```{r setup, message=FALSE, warning=FALSE}
# Suppress dplyr summarise grouping warning messages
options(dplyr.summarise.inform = FALSE)

# Load all required libraries
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(vip) # For variable importance plots
```

```{r load-data}
# Load the dataset
credit_card_df <- readRDS(url('https://gmubusinessanalytics.netlify.app/data/credit_card_df.rds'))

# Display a sample of the data to understand its structure
head(credit_card_df)
```

## 2. Exploratory Data Analysis (EDA)

Here, we investigate the data to uncover initial patterns and answer key business questions regarding customer attrition.

**Q: Do spend and transaction ratios affect customer status?**

**A:** Yes. Customers with lower spending and transaction ratios in Q4 compared to Q1 are more likely to have closed their accounts.

```{r eda-spend-transaction-ratio}
ggplot(credit_card_df, aes(x = transaction_ratio_q4_q1, y = spend_ratio_q4_q1, color = customer_status)) +
  geom_point(alpha = 0.5) +
  labs(
    title = 'Effect of Spend and Transaction Ratios on Customer Status',
    x = 'Transaction Ratio (Q4 vs Q1)',
    y = 'Spend Ratio (Q4 vs Q1)',
    color = 'Customer Status'
  ) +
  theme_light()
```

**Q: Are certain card types associated with higher closure rates?**

**A:** The 'Blue' card type accounts for over 90% of closed accounts.

```{r eda-card-type, message=FALSE}
credit_card_df %>% 
  filter(customer_status == 'closed_account') %>% 
  group_by(card_type) %>% 
  summarise(Closed_account_Count = n()) %>% 
  mutate(Closed_Percentage = (Closed_account_Count / sum(Closed_account_Count)) * 100) %>% 
  select(card_type, Closed_Percentage) %>% 
  arrange(desc(Closed_Percentage))
```

**Q: How long are customers typically loyal before closing an account?**

**A:** The average time a customer stays with the bank before closing an account is approximately 36 months.

```{r eda-loyalty}
credit_card_df %>% 
  filter(customer_status == 'closed_account') %>% 
  summarise(Avg_months_before_closing = mean(months_since_first_account))
```

**Q: Which education levels are most associated with account closures?**

**A:** Customers with Doctoral degrees have a higher closure rate compared to other education levels.

```{r eda-education-level, message=FALSE}
credit_card_df %>% 
  group_by(education, customer_status) %>% 
  summarise(customer_Count = n()) %>% 
  mutate(per = (customer_Count / sum(customer_Count)) * 100) %>%
  ggplot(aes(x = education, y = per, fill = customer_status)) +
  geom_bar(stat = 'identity', position = 'dodge') + 
  geom_text(aes(label = paste0(round(per), "%")), vjust = 1.5, position = position_dodge(0.9), size = 3) +
  labs(
    title = "Impact of Education Level on Customer Status",
    x = "Education Level",
    y = "Percentage of Customers"
  ) +
  theme_light()
```

**Q: How do closed accounts spread across different age groups?**

**A:** Customers in their 40s and 50s are more likely to close their accounts.

```{r eda-age-distribution}
credit_card_df %>% 
  filter(customer_status == 'closed_account') %>% 
  ggplot(aes(x = age)) +
  geom_density(fill = 'lightsteelblue1', alpha = 0.8) +
  labs(
    title = "Age Distribution for Closed Accounts",
    x = "Age"
  ) +
  theme_light()
```

## 3. Data Splitting & Preprocessing

We split the data into training and testing sets and define a feature engineering recipe that will be applied to all models.

```{r data-split}
set.seed(367821)
customer_split <- initial_split(credit_card_df, prop = 0.75, strata = customer_status)

customer_training <- training(customer_split)
customer_test <- testing(customer_split)

# Create cross-validation folds for tuning
set.seed(17897)
customer_folds <- vfold_cv(customer_training, v = 5)

# Define the metrics we care about
my_metrics <- metric_set(accuracy, roc_auc)
```

```{r feature-engineering}
# Define the feature engineering recipe
customer_recipe <- recipe(customer_status ~ ., data = customer_training) %>% 
  step_YeoJohnson(all_numeric(), -all_outcomes()) %>% 
  step_normalize(all_numeric(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes())

# Check the recipe
# customer_recipe %>% prep() %>% bake(new_data = NULL) %>% glimpse()
```

## 4. Model Training & Evaluation

We will define, train, and evaluate three different classification models: Logistic Regression, K-Nearest Neighbors (KNN), and Random Forest.

### Model 1: Logistic Regression

```{r model-logistic, message=FALSE, warning=FALSE}
# Define model
customer_logistic <- logistic_reg() %>% 
  set_engine('glm') %>% 
  set_mode('classification')

# Create workflow
logistic_wf <- workflow() %>%
  add_model(customer_logistic) %>% 
  add_recipe(customer_recipe)

# Fit to test set
log_last_fit <- logistic_wf %>% 
  last_fit(split = customer_split, metrics = my_metrics)
```

### Model 2: K-Nearest Neighbors (KNN)

```{r model-knn, message=FALSE, warning=FALSE}
# Define model
customer_knn <- nearest_neighbor(neighbors = tune()) %>% 
  set_engine('kknn') %>% 
  set_mode('classification')

# Create workflow
knn_wf <- workflow() %>% 
  add_model(customer_knn) %>% 
  add_recipe(customer_recipe)

# Tune workflow
knn_grid <- tibble(neighbors = c(12, 25, 40, 60, 80, 120))
set.seed(7698)
knn_tuning <- knn_wf %>% 
  tune_grid(resamples = customer_folds, grid = knn_grid)

# Finalize workflow with best K
best_k <- knn_tuning %>% select_best(metric = 'roc_auc')
final_knn_wf <- knn_wf %>% finalize_workflow(best_k)

# Fit to test set
knn_last_fit <- final_knn_wf %>% 
  last_fit(split = customer_split, metrics = my_metrics)
```

### Model 3: Random Forest

```{r model-random-forest, message=FALSE, warning=FALSE}
# Define model
customer_rf <- rand_forest(
  mtry = tune(),
  trees = tune(),
  min_n = tune()
) %>% 
  set_engine('ranger', importance = "impurity") %>% 
  set_mode('classification')

# Create workflow
rf_wf <- workflow() %>% 
  add_model(customer_rf) %>% 
  add_recipe(customer_recipe)

# Tune workflow
set.seed(8796)
rf_grid <- grid_random(
  mtry() %>% range_set(c(2, round(sqrt(ncol(customer_training))))),
  trees(),
  min_n(),
  size = 7
)
set.seed(9786)
rf_tuning <- rf_wf %>% 
  tune_grid(resamples = customer_folds, grid = rf_grid)

# Finalize workflow with best parameters
best_rf <- rf_tuning %>% select_best(metric = 'roc_auc')
final_rf_workflow <- rf_wf %>% finalize_workflow(best_rf)

# Fit to test set
rf_last_fit <- final_rf_workflow %>% 
  last_fit(split = customer_split, metrics = my_metrics)
```

## 5. Model Comparison & Final Selection

Now, we will compare the performance of the three models on the test set to select a winner.

```{r model-comparison}
# Collect metrics from all models and bind them into one table
model_comparison_tbl <- bind_rows(
  log_last_fit %>% collect_metrics() %>% mutate(model = "Logistic Regression"),
  knn_last_fit %>% collect_metrics() %>% mutate(model = "K-Nearest Neighbors"),
  rf_last_fit %>% collect_metrics() %>% mutate(model = "Random Forest")
)

# Display the comparison table
model_comparison_tbl %>% 
  select(model, .metric, .estimate) %>% 
  pivot_wider(names_from = .metric, values_from = .estimate)
```

**Conclusion:** The **Random Forest** model is the clear winner, with a near-perfect `roc_auc` of `r round(rf_last_fit %>% collect_metrics() %>% filter(.metric == 'roc_auc') %>% pull(.estimate), 4)`. We will select this as our final model.

### Final Model Analysis: Random Forest

Let's examine the ROC curve, confusion matrix, and variable importance for our chosen model.

```{r final-model-analysis}
# ROC Curve
rf_last_fit %>% 
  collect_predictions() %>% 
  roc_curve(truth = customer_status, estimate = .pred_closed_account) %>% 
  autoplot() +
  labs(title = "ROC Curve for Final Model (Random Forest)")

# Confusion Matrix
rf_last_fit %>% 
  collect_predictions() %>% 
  conf_mat(truth = customer_status, estimate = .pred_class)

# Variable Importance Plot
rf_last_fit %>% 
  extract_fit_parsnip() %>% 
  vip() +
  labs(title = "Top Predictors of Customer Attrition")
```
